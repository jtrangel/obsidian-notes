&copy [Rangel](https://github.com/jtrangel)
## Data Pipelines with Delta Live Tables

● Identify the components necessary to create a new DLT pipeline.

● Identify the purpose of the target and of the notebook libraries in creating a pipeline.

● Compare and contrast triggered and continuous pipelines in terms of cost and latency

● Identify which source location is utilizing Auto Loader.

● Identify a scenario in which Auto Loader is beneficial.

● Identify why Auto Loader has inferred all data to be STRING from a JSON source

● Identify the default behavior of a constraint violation

● Identify the impact of ON VIOLATION DROP ROW and ON VIOLATION FAIL UPDATE for a constraint violation

● Explain change data capture and the behavior of APPLY CHANGES INTO

● Query the events log to get metrics, perform audit logging, examine lineage.

● Troubleshoot DLT syntax: Identify which notebook in a DLT pipeline produced an error, identify the need for LIVE in create statement, identify the need for STREAM in from clause.